p8105_hw2_yx2954
================
Yiran Xu
2024-09-27

# Question 1

``` r
subway_df = read_csv("data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv", na = c("NA", "", ".")) |>
  select(Line, Station_Name = `Station Name`, Station_Latitude = `Station Latitude`, Station_Longitude = `Station Longitude`, Route1:Route11, Entry, Vending, Entrance_Type = `Entrance Type`, ADA) |>
  mutate(Entry = ifelse(Entry == "YES", TRUE, FALSE))|>
  janitor::clean_names()
```

``` r
head(subway_df)
```

    ## # A tibble: 6 × 19
    ##   line     station_name station_latitude station_longitude route1 route2 route3
    ##   <chr>    <chr>                   <dbl>             <dbl> <chr>  <chr>  <chr> 
    ## 1 4 Avenue 25th St                  40.7             -74.0 R      <NA>   <NA>  
    ## 2 4 Avenue 25th St                  40.7             -74.0 R      <NA>   <NA>  
    ## 3 4 Avenue 36th St                  40.7             -74.0 N      R      <NA>  
    ## 4 4 Avenue 36th St                  40.7             -74.0 N      R      <NA>  
    ## 5 4 Avenue 36th St                  40.7             -74.0 N      R      <NA>  
    ## 6 4 Avenue 45th St                  40.6             -74.0 R      <NA>   <NA>  
    ## # ℹ 12 more variables: route4 <chr>, route5 <chr>, route6 <chr>, route7 <chr>,
    ## #   route8 <dbl>, route9 <dbl>, route10 <dbl>, route11 <dbl>, entry <lgl>,
    ## #   vending <chr>, entrance_type <chr>, ada <lgl>

## Description

The original dataset contains different types of **variables**,
**including character**, **logical variable** and double-precision
floating point (**numeric variable**); As for the information, it
contains **detailed information about subway stations, including station
name, exact locations, the routes they serve, entrance/exit information,
ADA compliance, vending availability, staffing information, entrance
location, corner location and whether the station allows free
crossovers**. The original dataset has gone through a series of data
cleaning process, including **imputing missing data, data pruning,
converting the character variable of ADA to logical variable, and
normalizing the header into a more cleaning way**. The cleaned data has
a dimension of **1,868 × 32**. The data is not **tidy**, as the route
takes up 11 columns and too many “NA” inside.

## Answer the following questions using these data:

``` r
num_station = 
  subway_df |>
  distinct(line, station_name) |>
  nrow()

num_ada =
  subway_df |>
  filter(ada == TRUE) |>
  distinct(line, station_name) |>
  nrow()

prop_vending = subway_df |>
  filter(vending == "NO") |>
  summarise(proportion = mean(entry == TRUE)) |>
  pull(proportion)
```

There are **465** stations, **84** of them are ADA compliant,
**0.3770492** of station entrances / exits without vending allow
entrance

## Reformat data

``` r
subway_tidy_df = 
  subway_df |>
  mutate(across(route8:route11, as.character)) |>
  pivot_longer(
    cols = starts_with("route"),
    names_to = "route_number",  
    values_to = "route_name",   
    values_drop_na = TRUE      
  )
```

## Calculate number of A train station with ADA

``` r
num_a = 
  subway_tidy_df |>
  filter(route_name == "A") |>
  distinct(line, station_name) |>
  nrow()

num_a_ada =   
  subway_tidy_df |>
  filter(route_name == "A") |>
  filter(ada == TRUE) |>
  distinct(line, station_name) |>
  nrow()
```

**60** distinct stations serve the A train Of the stations that serve
the A train, **17** are ADA compliant

# Question 2

``` r
mr_df = read_excel("data/202309 Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel", range = "A2:N587", na = c("NA", "", ",")) |>
  filter(!is.na(Dumpster)) |>
  janitor::clean_names() |>
  mutate(sports_balls = as.integer(round(sports_balls, 0)), homes_powered = (
      weight_tons*500/30))

head(mr_df)
```

    ## # A tibble: 6 × 14
    ##   dumpster month year  date                weight_tons volume_cubic_yards
    ##      <dbl> <chr> <chr> <dttm>                    <dbl>              <dbl>
    ## 1        1 May   2014  2014-05-16 00:00:00        4.31                 18
    ## 2        2 May   2014  2014-05-16 00:00:00        2.74                 13
    ## 3        3 May   2014  2014-05-16 00:00:00        3.45                 15
    ## 4        4 May   2014  2014-05-17 00:00:00        3.1                  15
    ## 5        5 May   2014  2014-05-17 00:00:00        4.06                 18
    ## 6        6 May   2014  2014-05-20 00:00:00        2.71                 13
    ## # ℹ 8 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, sports_balls <int>, homes_powered <dbl>

Import other data frames

``` r
mr_df = mr_df |>
  mutate(trash_wheel = "Mr. Trash Wheel")

prof_df = read_excel("data/202309 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", range = "A2:M109", na = c("NA", "", ",")) |>
  filter(!is.na(Dumpster)) |>
  janitor::clean_names() |>
  mutate(year = as.character(year), trash_wheel = "Professor Trash Wheel", homes_powered = (
      weight_tons*500/30))

gwyn_df = read_excel("data/202309 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel", range = "A2:L159", skip = 1, na = c("NA", "", ",")) |>
  filter(!is.na(Dumpster)) |>
  janitor::clean_names() |>
  mutate(year = as.character(year), trash_wheel = "Gwynnda Trash Wheel",homes_powered = (
      weight_tons*500/30))
```

Combine all data frame

``` r
combined_df = bind_rows(mr_df, prof_df, gwyn_df) |>
  janitor::clean_names() |>
  arrange(date, dumpster) 
```

## data descrption

In total, the combined dataset contains **845** observations. Key
variables include the exact date when collecting data, the weight,
volume of different type of trash collected. The data collected by
different dumpster is denoted by the variable trash_wheel. It should be
noted that the three types of dumpster has differerent number of
variables. For Mr. Trash Wheel, it has **15** variables, while Professor
Trash Wheel and Gwynnda Trash Wheel has **14** and **13** variables,
respectively. The total weight of trash collected by Professor Trash
Wheel was **216.26** tons. The total number of cigarette butts collected
by Gwynnda in June of 2022 **1.812^{4}**

# Qustion 3

## Import data

``` r
bakers_df = read_csv(file = "data/gbb_datasets/bakers.csv", na = c("NA", "", ".")) |>
  janitor::clean_names() |>
  mutate(baker = baker_name) |>
  select(-baker_name)    

bakes_df = read_csv(file = "data/gbb_datasets/bakes.csv", , na = c("NA", "", ".")) |>
  janitor::clean_names()

results_df = read_csv(file = "data/gbb_datasets/results.csv", skip = 2, na = c("NA", "", ".")) |>
  janitor::clean_names()
```

## Check completeness and correctness:

It can be noted that the names provided in bakers_df are full names,
while names in bakes_df and results_df are only the first name. In order
to match the names, we should first convert the full name to first name
in the bakers_df, and then match the exact baker by name, series, and
episode.

``` r
bakers_df = bakers_df |>
  mutate(baker = str_split(baker, " ", simplify = TRUE)[,1])
```

check correctness

``` r
anti_join(bakes_df, bakers_df, by = "baker", "series")
```

    ## # A tibble: 8 × 5
    ##   series episode baker    signature_bake                            show_stopper
    ##    <dbl>   <dbl> <chr>    <chr>                                     <chr>       
    ## 1      2       1 "\"Jo\"" Chocolate Orange CupcakesOrange and Card… Chocolate a…
    ## 2      2       2 "\"Jo\"" Caramelised Onion, Gruyere and Thyme Qui… Raspberry a…
    ## 3      2       3 "\"Jo\"" Stromboli flavored with Mozzarella, Ham,… Unknown     
    ## 4      2       4 "\"Jo\"" Lavender Biscuits                         Blueberry M…
    ## 5      2       5 "\"Jo\"" Salmon and Asparagus Pie                  Apple and R…
    ## 6      2       6 "\"Jo\"" Rum and Raisin Baked Cheesecake           Limoncello …
    ## 7      2       7 "\"Jo\"" Raspberry & Strawberry Mousse Cake        Pain Aux Ra…
    ## 8      2       8 "\"Jo\"" Raspberry and Blueberry Mille Feuille     Mini Victor…

``` r
anti_join(bakers_df, results_df, by = "baker", "series")
```

    ## # A tibble: 1 × 5
    ##   series baker_age baker_occupation hometown     baker
    ##    <dbl>     <dbl> <chr>            <chr>        <chr>
    ## 1      2        41 Housewife        Ongar, Essex Jo

``` r
anti_join(results_df, bakers_df, by = "baker", "series")
```

    ## # A tibble: 8 × 5
    ##   series episode baker  technical result    
    ##    <dbl>   <dbl> <chr>      <dbl> <chr>     
    ## 1      2       1 Joanne        11 IN        
    ## 2      2       2 Joanne        10 IN        
    ## 3      2       3 Joanne         1 IN        
    ## 4      2       4 Joanne         8 IN        
    ## 5      2       5 Joanne         6 IN        
    ## 6      2       6 Joanne         1 STAR BAKER
    ## 7      2       7 Joanne         3 IN        
    ## 8      2       8 Joanne         1 WINNER

Comparing the results abve, we may infer that **“Jo”** in **bakes_df**,
**Jo** in **bakers_df**, and **Joanne** in **results_df** are the same
person, as they both showed in series 2, and remained from episode 1 to
8.

``` r
bakes_df = 
  bakes_df |>
  mutate(baker = ifelse(baker == '"Jo"', "Jo", baker))

results_df = 
  results_df  |>
  mutate(baker = ifelse(baker == "Joanne", "Jo", baker))

anti_join(bakes_df, bakers_df, by = "baker", "series")
```

    ## # A tibble: 0 × 5
    ## # ℹ 5 variables: series <dbl>, episode <dbl>, baker <chr>,
    ## #   signature_bake <chr>, show_stopper <chr>

``` r
anti_join(results_df, bakers_df, by = "baker", "series")
```

    ## # A tibble: 0 × 5
    ## # ℹ 5 variables: series <dbl>, episode <dbl>, baker <chr>, technical <dbl>,
    ## #   result <chr>

Now we have improved the correctness of these dataframe, making
bakers_df the full list of name. Now check the result of **anti_join**
for **results_df** and **bakes_df**

``` r
anti_join(results_df, bakes_df, by = c("baker", "series", "episode"))
```

    ## # A tibble: 588 × 5
    ##    series episode baker    technical result
    ##     <dbl>   <dbl> <chr>        <dbl> <chr> 
    ##  1      1       2 Lea             NA <NA>  
    ##  2      1       2 Mark            NA <NA>  
    ##  3      1       3 Annetha         NA <NA>  
    ##  4      1       3 Lea             NA <NA>  
    ##  5      1       3 Louise          NA <NA>  
    ##  6      1       3 Mark            NA <NA>  
    ##  7      1       4 Annetha         NA <NA>  
    ##  8      1       4 Jonathan        NA <NA>  
    ##  9      1       4 Lea             NA <NA>  
    ## 10      1       4 Louise          NA <NA>  
    ## # ℹ 578 more rows

``` r
anti_join(bakes_df, results_df, by = c("baker", "series", "episode"))
```

    ## # A tibble: 0 × 5
    ## # ℹ 5 variables: series <dbl>, episode <dbl>, baker <chr>,
    ## #   signature_bake <chr>, show_stopper <chr>

Many missing info are showed in **bakes_df**, while **results_df**
contains all observations in **bakes_df**. Then we should merge
**bakes_df** to **results_df** to avoid lost of info.

``` r
merge_df = results_df |>
  left_join(bakes_df, by = c("baker", "series", "episode"))
```

As **bakers_df** contains all participant info, we should further merge
the data frame to **bakers_df**

``` r
merge_df = bakers_df |>
  left_join(results_df, c("baker", "series")) |>
  select(baker, result, series, episode, everything()) |>
  arrange(series, episode)

write.csv(merge_df, file = "data/gbb_datasets/merged.csv")
```

## Data cleaning process

- 1.  Important datasets

  - Briefly go over three datasets, it is found that the header for
    baker name in **bakers_df** is **“baker_name”**, while it in other
    data frames are **“baker”**. Should first change the header to the
    same by **“mutate()”** function before merging.
  - **“janitor:clean_names()”** was also applied to adjust the header to
    be more readable. For **results_df**, it was noticed that first two
    rows are either blank or notes. Therefore I deleted these rows by
    **“skip()”**

- 2.  Check completeness and correctness – By **anti_join()**

  - The name shown in **bakers_df** were full names, while they were
    first names in other data frames. Should first convert full name to
    first name before merging.
  - By checking missing names in **results_df** and **bakers_df**
    against **bakers_df**, I found that the name **“Jo”** and **Joanne**
    could be the same person with **Jo** in **bakers_df** by typing
    error, as **“Jo”** and **Joanne”** show up in exact same episodes,
    and there is no person named **Joanne** in **baker_df**. Therefore
    change the name to **Jo** by **mutate() and **ifelse()\*\* function.
  - Further doing mutual check, I found that the proportion of missing
    info is sorted by: **bakers_df** \> **results_df** \> **bakers_df**.
    Also, all bakers in **bakes_df** can be found in **results_df**, all
    bakers in **results_df** can be found in **bakers_df**. Therefore,
    should first merge the smallest data frame to the medium one, and
    eventually to the largest on, i.e **bakes_df** to **results_df** to
    **bakers_df**.

- 3.  Merged into final dataset

  - Finally rearrange the order of variable and observations to make it
    more reasonable. In specific, I put importan information, including
    name, the episode they are involved and result in the front, and
    left less important information in the back.

- 4.  Brief description of final dataset

  - The dimensions of the dataframe are **1136** rows and **8** columns.
    **8** variables are bakers’ name, age, occupation, hometown, and the
    series, episodes they were involved in, as well as the scores and
    results.

## Create a reader-friendly table showing the star baker or winner of each episode in Seasons 5 through 10

``` r
starWin_df = merge_df |>
  filter(series >= 5, series <= 10) |>
  filter(result %in% c("STAR BAKER", "WINNER")) |>
  select(baker, result, series, episode, everything()) |>
  arrange(series, episode)
```

## Comment on table

According to the data, usually the winner in the final episode will be
selected from star bakers. Besides, intuitively, one have more chance to
be winner if he/she get the most star baker honor. Howerver, two
surprise are observed:

- 1.  the winner of series 5 is not Richard, who won the most star
      baker, but Nancy, who only won the star baker once.
- 2.  the winner of series 10 is David, who never won star baker before.

## Import, clean, tidy, and organize the viewership data in viewers.csv

``` r
viewer_df = read_csv(file = "data/gbb_datasets/viewers.csv", na = c("NA", "", ".")) |>
  janitor::clean_names() |>
  pivot_longer(
    cols = starts_with("series"),
    names_to = "series_number",
    values_to = "viewers",
    values_drop_na = TRUE  
  )

head(viewer_df, 10)
```

    ## # A tibble: 10 × 3
    ##    episode series_number viewers
    ##      <dbl> <chr>           <dbl>
    ##  1       1 series_1         2.24
    ##  2       1 series_2         3.1 
    ##  3       1 series_3         3.85
    ##  4       1 series_4         6.6 
    ##  5       1 series_5         8.51
    ##  6       1 series_6        11.6 
    ##  7       1 series_7        13.6 
    ##  8       1 series_8         9.46
    ##  9       1 series_9         9.55
    ## 10       1 series_10        9.62

The overall viewership in Season 1 is **2.77**, and **10.0393** in
Season 5
