---
title: "p8105_hw2_yx2954"
author: "Yiran Xu"
date: "2024-09-27"
output: github_document
---

# Question 1

```{r, echo = FALSE, message = FALSE}
library(dplyr)
library(readr)
library(tidyr)
library(readxl)
library(tidyverse)
library(stringr)
```

```{r}
subway_df = read_csv("data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv", na = c("NA", "", ".")) |>
  select(Line, Station_Name = `Station Name`, Station_Latitude = `Station Latitude`, Station_Longitude = `Station Longitude`, Route1:Route11, Entry, Vending, Entrance_Type = `Entrance Type`, ADA) |>
  mutate(Entry = ifelse(Entry == "YES", TRUE, FALSE))|>
  janitor::clean_names()

head(subway_df)
```

## Description

The original dataset contains different types of **variables**, **including character**, **logical variable** and double-precision floating point (**numeric variable**); As for the information, it contains **detailed information about subway stations, including station name, exact locations, the routes they serve, entrance/exit information, ADA compliance, vending availability, staffing information, entrance location, corner location and whether the station allows free crossovers**.
The original dataset has gone through a series of data cleaning process, including **imputing missing data, data pruning, converting the character variable of ADA to logical variable, and normalizing the header into a more cleaning way**. The cleaned data has a dimension of **1,868 Ã— 32**. The data is **tidy**, as now each value in the entry is finely positioned without mixing.

## Answer the following questions using these data:

```{r}
num_station = 
  subway_df |>
  distinct(line, station_name) |>
  nrow()

num_ada =
  subway_df |>
  filter(ada == TRUE) |>
  distinct(line, station_name) |>
  nrow()

prop_vending = subway_df |>
  filter(vending == "NO") |>
  summarise(proportion = mean(entry == TRUE)) |>
  pull(proportion)
```

There are **`r num_station`** stations, **`r num_ada`** of them are ADA compliant, **`r prop_vending`** of station entrances / exits without vending allow entrance

## Reformat data

```{r}
subway_tidy_df = 
  subway_df |>
  mutate(across(route8:route11, as.character)) |>
  pivot_longer(
    cols = starts_with("route"),
    names_to = "route_number",  
    values_to = "route_name",   
    values_drop_na = TRUE      
  )
```

Calculate number of A train station with ADA

```{r}
num_a_ada = 
  subway_tidy_df |>
  filter(route_name == "A") |>
  filter(ada == TRUE) |>
  nrow()
```

Of the stations that serve the A train, **`r num_a_ada`** are ADA compliant


# Question 2

```{r}
mr_df = read_excel("data/202309 Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel", range = "A2:N587", na = c("NA", "", ",")) |>
  filter(!is.na(Dumpster)) |>
  janitor::clean_names() |>
  mutate(sports_balls = as.integer(round(sports_balls, 0)), homes_powered = (
      weight_tons*500/30))

head(mr_df)
```

Import other data frames

```{r}
mr_df = mr_df |>
  mutate(trash_wheel = "Mr. Trash Wheel")

prof_df = read_excel("data/202309 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", range = "A2:M109", na = c("NA", "", ",")) |>
  filter(!is.na(Dumpster)) |>
  janitor::clean_names() |>
  mutate(year = as.character(year), trash_wheel = "Professor Trash Wheel", homes_powered = (
      weight_tons*500/30))

gwyn_df = read_excel("data/202309 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel", range = "A2:L159", skip = 1, na = c("NA", "", ",")) |>
  filter(!is.na(Dumpster)) |>
  janitor::clean_names() |>
  mutate(year = as.character(year), trash_wheel = "Gwynnda Trash Wheel",homes_powered = (
      weight_tons*500/30))
```

Combine all data frame

```{r}
combined_df = bind_rows(mr_df, prof_df, gwyn_df) |>
  janitor::clean_names() |>
  arrange(date, dumpster) 
```

## data descrption

In total, the combined dataset contains **`r nrow(combined_df)`** observations. Key variables include the exact date when collecting data, the weight, volume of different type of trash collected. The data collected by different dumpster is denoted by the variable trash_wheel. It should be noted that the three types of dumpster has differerent number of variables. For Mr. Trash Wheel, it has **`r ncol(mr_df)`** variables, while Professor Trash Wheel and Gwynnda Trash Wheel has **`r ncol(prof_df)`** and **`r ncol(gwyn_df)`** variables, respectively.
The total weight of trash collected by Professor Trash Wheel was **`r sum(pull(mr_df, weight_tons))`** tons. The total number of cigarette butts collected by Gwynnda in June of 2022 **`r sum(gwyn_df |> filter(year == 2022, month == "June") |> pull(cigarette_butts))`**


# Qustion 3

## Import data

```{r}

bakers_df = read_csv(file = "data/gbb_datasets/bakers.csv", na = c("NA", "", ".")) |>
  janitor::clean_names() |>
  mutate(baker = baker_name) |>
  select(-baker_name)    

bakes_df = read_csv(file = "data/gbb_datasets/bakes.csv", , na = c("NA", "", ".")) |>
  janitor::clean_names()

results_df = read_csv(file = "data/gbb_datasets/results.csv", skip = 2, na = c("NA", "", ".")) |>
  janitor::clean_names()

```

## Check completeness and correctness:

It can be noted that the names provided in bakers_df are full names, while names in bakes_df and results_df are only the first name. In order to match the names, we should first convert the full name to first name in the bakers_df, and then match the exact baker by name, series, and episode.

```{r}
bakers_df = bakers_df |>
  mutate(baker = str_split(baker, " ", simplify = TRUE)[,1])
```

check correctness

```{r}
anti_join(bakes_df, bakers_df, by = "baker", "series")
anti_join(bakers_df, results_df, by = "baker", "series")
anti_join(results_df, bakers_df, by = "baker", "series")

```

Comparing the results abve, we may infer that **"Jo"** in **bakes_df**, **Jo** in **bakers_df**, and **Joanne** in **results_df** are the same person, as they both showed in series 2, and remained from episode 1 to 8. 

```{r}
bakes_df = 
  bakes_df |>
  mutate(baker = ifelse(baker == '"Jo"', "Jo", baker))

results_df = 
  results_df  |>
  mutate(baker = ifelse(baker == "Joanne", "Jo", baker))

anti_join(bakes_df, bakers_df, by = "baker", "series")
anti_join(results_df, bakers_df, by = "baker", "series")

```

Now we have improved the correctness of these dataframe, making bakers_df the full list of name. Now check the result of **anti_join** for **results_df** and **bakes_df**

```{r}
anti_join(results_df, bakes_df, by = c("baker", "series", "episode"))
anti_join(bakes_df, results_df, by = c("baker", "series", "episode"))
```

Many missing info are showed in **bakes_df**, while **results_df** contains all observations in **bakes_df**. Then we should merge **bakes_df** to **results_df** to avoid lost of info.

```{r}
merge_df = results_df |>
  left_join(bakes_df, by = c("baker", "series", "episode"))
```

As **bakers_df** contains all participant info, we should further merge the data frame to **bakers_df**

```{r}
merge_df = bakers_df |>
  left_join(results_df, c("baker", "series")) |>
  select(baker, result, series, episode, everything()) |>
  arrange(series, episode)

write.csv(merge_df, file = "data/gbb_datasets/merged.csv")

```


## Data cleaning process
*   1. Important datasets
    * Briefly go over three datasets, it is found that the header for baker name in **bakers_df** is **"baker_name"**, while it in other data frames are **"baker"**. Should first change the header to the same by **"mutate()"** function before merging.
    * **"janitor:clean_names()"** was also applied to adjust the header to be more readable. For **results_df**, it was noticed that first two rows are either blank or notes. Therefore I deleted these rows by **"skip()"**

*   2. Check completeness and correctness -- By **anti_join()**
    * The name shown in **bakers_df** were full names, while they were first names in other data frames. Should first convert full name to first name before merging.
    * By checking missing names in **results_df** and **bakers_df** against **bakers_df**, I found that the name **"Jo"** and **Joanne** could be **Jo** in **bakers_df** by typing error. Therefore change the name to **Jo** by **mutate() and **ifelse()** function. 
    * Further doing mutual check, I found that the proportion of missing info is sorted by: **bakers_df** > **results_df** > **bakers_df**. Also, all bakers in **bakes_df** can be found in **results_df**, all bakers in **results_df** can be found in **bakers_df**. Therefore, should first merge the smallest data frame to the medium one, and eventually to the largest on, i.e **bakes_df** to **results_df** to **bakers_df**. 

*   3. Merged into final dataset
    * Finally rearrange the order of variable and observations to make it more reasonable. In specific, I put importan information, including name, the episode they are involved and result in the front, and left less important information in the back.
    
*   4. Brief description of final dataset
    * The dimensions of the dataframe are **`r nrow(merge_df)`** rows and **`r ncol(merge_df)`** columns. **`r ncol(merge_df)`** variables are bakers' name, age, occupation, hometown, and the series, episodes they were involved in, as well as the scores and results.




